Investigación sobre DBSCAN como algoritmo no supervisado

Para complementar el análisis de agrupamiento en los datos de desempeño estudiantil, se evaluó el uso del algoritmo DBSCAN (Density-Based Spatial Clustering of Applications with Noise). Este es un método de clustering basado en densidad, que no requiere especificar el número de clusters (k) de antemano, a diferencia de KMeans o Spectral Clustering.

Modelo matemático de DBSCAN

DBSCAN agrupa puntos en regiones de alta densidad y clasifica como outliers aquellos que se encuentran en zonas de baja densidad. Los parámetros principales son:

eps (ε): radio de vecindad, es decir, la distancia máxima para que dos puntos se consideren vecinos.

min_samples: número mínimo de puntos necesarios en el vecindario para formar un cluster.

El algoritmo comienza seleccionando un punto no visitado y determina si tiene al menos min_samples puntos dentro de la distancia eps. Si es así, se forma un cluster y se expanden los puntos vecinos densos. De lo contrario, el punto se clasifica como ruido (outlier). Así, DBSCAN identifica automáticamente grupos de forma arbitraria y detecta valores atípicos.

Por qué DBSCAN conviene para estos datos

En el conjunto de datos estudiantil, las características como tiempo de estudio, ausencias, calificaciones parciales y número de reprobaciones presentan heterogeneidad y posibles outliers, como alumnos con ausencias extremas o bajo rendimiento muy marcado.

DBSCAN es especialmente útil en este contexto porque:

No requiere conocer a priori el número de clusters, lo cual es práctico dado que no se sabe cuántos perfiles de estudiantes podrían existir.

Detecta automáticamente outliers o casos atípicos, ayudando a identificar estudiantes con comportamientos extremos (por ejemplo, altos niveles de ausencias).

Puede encontrar clusters con formas arbitrarias, no limitándose a agrupamientos esféricos como KMeans.

En resumen, DBSCAN aporta un enfoque robusto para segmentar los estudiantes en perfiles claros y detectar casos atípicos, facilitando una mejor interpretación y posible intervención educativa.

---

Elección del número de grupos: Silhouette Score aplicado a DBSCAN

Para determinar la cantidad óptima de grupos en los datos, se utilizó la métrica Silhouette Score, que mide qué tan bien definidos están los clusters. El valor oscila entre -1 (muy mal agrupado) y 1 (perfectamente agrupado). Se probó el algoritmo DBSCAN con diferentes valores del parámetro eps, ya que este define el radio de vecindad para formar clusters.

Los resultados fueron:

eps=0.5: 9 clusters, Silhouette Score = -0.248 (demasiados grupos, mal definidos).

eps=1.0: 4 clusters, Silhouette Score = 0.020 (ligera mejora).

eps=1.5: 2 clusters, Silhouette Score = 0.339 (mejor estructura).

eps=2.0: 2 clusters, Silhouette Score = 0.468, el valor más alto.

Con esto, se concluye que el valor eps=2.0 genera la mejor separación de grupos, con dos perfiles bien definidos de estudiantes, además de detectar 13 outliers relevantes.

---

## Aplicación de un algoritmo no supervisado para descubrir estructuras subyacentes

Se utilizó el algoritmo **DBSCAN** (*Density-Based Spatial Clustering of Applications with Noise*), un método de agrupamiento no supervisado que permite encontrar grupos en los datos sin necesidad de definir previamente el número de clusters. Además, DBSCAN identifica puntos atípicos (*outliers*) de forma automática.

Este algoritmo fue aplicado a las siguientes variables relacionadas con el rendimiento académico de los estudiantes:  
**`studytime`, `absences`, `failures`, `G1`, `G2`, `G3`**.  
Antes del clustering, los datos fueron estandarizados usando `StandardScaler`, debido a que DBSCAN es sensible a la escala de las variables.

Se probaron diferentes valores del parámetro `eps` para observar cómo cambiaba la cantidad de clusters encontrados. También se evaluó cada agrupación utilizando la métrica **Silhouette Score**, que indica qué tan bien definidos están los grupos. A continuación, se resumen los resultados:

| `eps` | Clusters encontrados | Outliers | Silhouette Score |
|-------|----------------------|----------|------------------|
| 0.5   | 9                    | 306      | -0.248          |
| 1.0   | 4                    | 143      | 0.020           |
| 1.5   | 2                    | 58       | 0.339           |
| 2.0   | 2                    | 13       | **0.468**      |


## Discusión de la métrica y número de clusters

Para determinar el número óptimo de grupos, se utilizó la métrica **Silhouette Score**, la cual mide qué tan bien se ajusta cada punto a su grupo (valor ideal cercano a 1).

El valor más alto obtenido fue **0.468 con `eps = 2.0`**, lo que indica una lo que indica una buena estructura de agrupamiento. Este resultado sugiere la existencia de **dos perfiles principales de estudiantes**, diferenciados por su rendimiento académico y comportamiento (por ejemplo, número de materias reprobadas o faltas), además de un pequeño grupo de casos atípicos que podrían requerir atención especial.

---

## Estrategia para determinar el número de grupos

Se utilizó la métrica **Silhouette Score** como estrategia para identificar la cantidad óptima de grupos en los datos. Esta métrica evalúa qué tan bien está asignado cada punto dentro de su grupo, considerando la cohesión (qué tan cerca está de su cluster) y la separación (qué tan lejos está de otros clusters).

Para cada valor de `eps` probado en el algoritmo DBSCAN, se calculó el Silhouette Score. El mejor resultado se obtuvo con `eps = 2.0`, alcanzando un score de **0.468**, lo cual indica una buena estructura de agrupamiento. Esto sugiere que existen **2 clusters bien definidos** y un pequeño conjunto de puntos atípicos.

Se eligió esta métrica porque es adecuada para algoritmos como DBSCAN, que pueden generar clusters de forma arbitraria y con tamaños variables.
