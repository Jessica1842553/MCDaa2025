\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{float}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{array}
\usepackage{caption}
\usepackage[square,numbers]{natbib}
\usepackage[table,xcdraw]{xcolor}
\usepackage[round]{natbib}
\usepackage{amsmath}
\usepackage[absolute,overlay]{textpos}
\usepackage{setspace}
\decimalpoint


\usepackage[hyphens]{url}
\usepackage[hidelinks]{hyperref}
\usepackage{breakurl}
\urlstyle{same}   

\usepackage{ebgaramond}   % Fuente del contenido
\usepackage{helvet}       % Para títulos de secciones
\renewcommand{\familydefault}{\rmdefault}
\usepackage{sectsty}
\allsectionsfont{\sffamily\bfseries} 

\newcommand{\TitleStyleOne}[1]{\bfseries\sffamily #1}

\begin{document}

\begin{textblock*}{9cm}(\dimexpr0.5\paperwidth-4.5cm\relax,2cm)
\color{black}
\centering
\footnotesize\textbf{Universidad Autónoma de Nuevo León}\\
\footnotesize Maestría en Ciencia de Datos\\
\footnotesize Aprendizaje Automático
\end{textblock*}

\vspace*{-1cm}

\begin{center}
    \resizebox{\textwidth}{!}{\TitleStyleOne{Predicción del rendimiento académico}}\\[0.5em]
    
    % Línea fina debajo del título
    \rule{0.65\textwidth}{0.35pt}\\[0.7em]
    
    % Datos
    {Jessica Lizeth Hernández Bracho -- 1842553}\\[0.3em]
    {\today}
\end{center}

\vspace{1cm} 

\section{Introducción}

El rendimiento académico de los estudiantes es un tema de interés constante en el ámbito educativo, ya que permite identificar los factores que influyen en el desempeño y, a partir de ello, diseñar estrategias que favorezcan la mejora del aprendizaje. En este contexto, el presente estudio se basa en el conjunto de datos Student Performance disponible en el repositorio UCI Machine Learning Repository, el cual recopila información académica, demográfica y social de estudiantes de secundaria de Portugal.


Particularmente, se trabajará con información correspondiente a la asignatura de Matemáticas, que contiene datos de aproximadamente 395 estudiantes y un total de 33 variables, las cuales abarcan aspectos personales, familiares, escolares y académicos.


Este estudio combina enfoques estadísticos y de aprendizaje automático para ofrecer una visión integral sobre los factores que afectan el rendimiento académico, contribuyendo al entendimiento de cómo ciertas variables pueden influir significativamente en los resultados educativos.


\section{Descripción de los datos}

"Student Performance Data Set" del UCI Machine Learning Repository, recopilado por \citeauthor{student_performance_320} \citeyear{student_performance_320}, contiene información sobre estudiantes de secundaria en Portugal, incluyendo variables personales, familiares, escolares y las calificaciones obtenidas en distintos periodos.


Para este trabajo, se seleccionaron únicamente las variables directamente asociadas al rendimiento académico con el fin de realizar análisis exploratorios, pruebas de hipótesis, selección de características y la construcción de modelos predictivos.

\subsection*{Datos}

\subsubsection*{Datos Personales del Estudiante}

\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|}
\hline
\rowcolor[HTML]{DAE8FC} 
\textbf{Variable} & \textbf{Descripción}                                & \textbf{Tipo} \\ \hline
sex               & Género del estudiante (F = femenino, M = masculino) & Categórica    \\ \hline
age               & Edad del estudiante (15 a 22 años)                  & Numérica      \\ \hline
address           & Tipo de residencia (U = urbana, R = rural)          & Categórica    \\ \hline
famsize & Tamaño de la familia (LE3 = ≤3, GT3 = \textgreater{}3 miembros) & Categórica \\ \hline
\end{tabular}%
}
\caption{Datos personales del estudiante}
\label{tab:datos_personales}
\end{table}

\subsubsection*{Contexto Familiar}

\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|}
\hline
\rowcolor[HTML]{DAE8FC} 
\textbf{Variable} & \textbf{Descripción}                                       & \textbf{Tipo}    \\ \hline
Medu              & Nivel educativo de la madre (0: ninguno, 4: universitario) & Numérica ordinal \\ \hline
Fedu              & Nivel educativo del padre (0: ninguno, 4: universitario)   & Numérica ordinal \\ \hline
Mjob              & Trabajo de la madre (teacher, health, etc.)                & Categórica       \\ \hline
Fjob              & Trabajo del padre                                          & Categórica       \\ \hline
guardian          & Tutor principal del estudiante (mother, father, other)     & Categórica       \\ \hline
\end{tabular}%
}
\caption{Contexto familiar}
\label{tab:contexto_familiar}
\end{table}

\subsubsection*{Información Escolar}

\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|}
\hline
\rowcolor[HTML]{DAE8FC} 
\textbf{Variable} & \textbf{Descripción}                               & \textbf{Tipo}    \\ \hline
studytime        & Tiempo de estudio semanal (1: $<$2h, 4: $>$10h)    & Numérica ordinal \\ \hline
failures         & Número de materias reprobadas (0–3)                & Numérica         \\ \hline
schoolsup        & Apoyo educativo adicional en la escuela (yes o no) & Categórica       \\ \hline
famsup           & Apoyo educativo familiar (yes o no)                & Categórica       \\ \hline
internet         & Acceso a internet en casa (yes o no)               & Categórica       \\ \hline
\end{tabular}%
}
\caption{Información escolar}
\label{tab:informacion_escolar}
\end{table}

\subsubsection*{Factores de Comportamiento y Hábitos}

\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|}
\hline
\rowcolor[HTML]{DAE8FC} 
\textbf{Variable} & \textbf{Descripción}                                  & \textbf{Tipo}    \\ \hline
activities       & Participa en actividades extracurriculares (yes o no) & Categórica       \\ \hline
goout            & Frecuencia con la que sale con amigos (1–5)           & Numérica ordinal \\ \hline
freetime         & Tiempo libre despúes de la escuela (1–5)              & Numérica ordinal \\ \hline
Walc             & Consumo de alcohol en fin de semana (1–5)             & Numérica ordinal \\ \hline
health           & Estado de salud autoevaluado (1–5)                    & Numérica ordinal \\ \hline
\end{tabular}%
}
\caption{Factores de comportamiento y hábitos}
\label{tab:factores_comportamiento}
\end{table}

\subsubsection*{Rendimiento Académico}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\rowcolor[HTML]{DAE8FC} 
\textbf{Variable} & \textbf{Descripción}                       & \textbf{Tipo} \\ \hline
G1                & Nota obtenida en el primer periodo (0–20)  & Numérica      \\ \hline
G2                & Nota obtenida en el segundo periodo (0–20) & Numérica      \\ \hline
G3                & Nota final (tercer periodo) (0–20)         & Numérica      \\ \hline
\end{tabular}
\caption{Rendimiento académico}
\label{tab:rendimiento_academico}
\end{table}


\section{Antecedentes}

Los alumnos que obtienen un buen rendimiento académico son aquellos que alcanzan calificaciones óptimas para aprobar sus asignaturas, siendo una medida para valorar sus capacidades, que expresa lo aprendido durante su preparación. En este ámbito, existen varios factores relacionados con el rendimiento académico de los estudiantes y la calidad de la educación superior, entre los cuales se destacan: la infraestructura educativa, el sistema de evaluación docente, el entorno social, familiar y económico del
estudiante, la malla curricular, entre otros que inciden en su propio rendimiento y la calidad de la educación.


Existen diversas investigaciones que abordan el análisis de este tipo de datos, una publicación particularmente relevante es la de \citeauthor{RamirezLemus2023}~\citep{RamirezLemus2023}, en donde se propone un enfoque similar al que se plantea en este trabajo, pues se evalúan distintas combinaciones y análisis al conjunto de datos con enfoque cuantitativo.
 

\section{Metodología}

El análisis se desarrollará a través de los siguientes pasos:
\begin{enumerate}[label=\textbf{\arabic*.}]
    \item \underline{\textbf{{Evaluación del tipo de variable:}}} 
    
    
    Inicialmente se seleccionó las siguientes variables de interés para el análisis, por la importancia dentro del tema:
    \begin{itemize}[label=\--] % Guion doble como viñeta
    \item \textbf{Age:} Edad del estudiante.
    \item \textbf{Studytime:} Tiempo dedicado al estudio.
    \item \textbf{Failures:} Número de materias reprobadas anteriormente.
    \item \textbf{Absences:} Número de faltas.
    \item \textbf{G1, G2, G3:} Calificaciones de los tres periodos (G3 representa la calificación final).
    \end{itemize}
    
    Se utilizó un gráfico Q-Q (Quantile-Quantile) para visualizar la distribución de cada variable y determinar si son o no paramétricas.

    \item \underline{\textbf{Estadística descriptiva:}} Se calcularon medidas descriptivas (media, mediana, desviación estándar, mínimos y máximos) para cada variable, con el objetivo de observar el comportamiento general de los datos.

    \item \underline{\textbf{Matriz de correlación:}} Se construyó una matriz de correlación entre las variables, lo que permitirá identificar relaciones lineales entre ellas. 
    
    Se interpretarán acerca de las correlaciones más significativas, especialmente aquellas que puedan incidir en el rendimiento académico (G3).

    \item \underline{\textbf{Pruebas de hipótesis:}} A partir de las correlaciones observadas, se propone una hipótesis estadística, con el fin de determinar si cierta variable tiene un impacto significativo sobre la nota final del estudiante.


    Se realizó una prueba no paramétrica de Mann-Whitney U para comparar las calificaciones finales (G3) entre dos grupos de estudiantes:
    \begin{itemize}[label=\--] % Guion doble como viñeta
    \item Grupo con número de faltas bajas (menos que la media de faltas).
    \item Grupo con número de faltas altas (mayor o igual que la media de faltas).
    \end{itemize}

    Se elaboró un diagrama de caja comparando las calificaciones finales entre los dos grupos definidos anteriormente. {\textit{(Fig.~\ref{fig:boxplot}, pág.~\pageref{fig:boxplot})}}
    
    \item \underline{\textbf{Selección de características:}} Se realiza una etapa de selección de variables para identificar las características más relevantes que permiten predecir la calificación final G3. Esta fase fue crucial para reducir la dimensión del problema y así, mejorar la precisión del modelo.
    
    
    Se utilizaron los siguientes métodos:
    \begin{enumerate}[label=\textbf{\roman*.}]
    \item {\textbf{Transformación de variables categóricas}} 
    
    
    Se convirtieron variables con valores tipo 'yes'/'no' a formato binario (1/0) para ser utilizadas por los modelos. Por ejemplo: higher, internet, schoolsup, entre otras.
    \item {\textbf{Análisis de varianza (ANOVA - Valor F)}} 
    
    
    Se aplicó la prueba F de regresión (\texttt{f\_regression}) para evaluar la relevancia estadística lineal de cada variable con respecto a G3. Las variables con p-valor inferiores a un umbral de significancia de $\alpha$ = 0.05 fueron consideradas relevantes.
    \item {\textbf{Umbral de varianza}} 
    
    
    Se utilizó el método VarianceThreshold para descartar variables con muy baja dispersión, ya que estas no aportan suficiente información al modelo.
    \item {\textbf{Información mutua}} 
    
    
    Se aplicó la métrica de \texttt{'mutual\_info\_regression'} para capturar relaciones no lineales entre las variables predictoras y la variable objetivo.
    \item {\textbf{Selección exhaustiva de características (EFS)}} 
    
    
    Se utilizó el método Exhaustive Feature Selector junto con regresión lineal como estimador, este método prueba todas las combinaciones posibles de variables dentro de un rango definido y selecciona el subconjunto que maximiza el rendimiento (en este caso, minimiza el MAE).
    \end{enumerate}
    
    \item \underline{\textbf{Agrupamiento de datos:}} 
    Por lo aplicado en la sección anterior, se restablecen las variables a trabajar y las variables fueron estandarizadas utilizando StandardScaler, con el fin de evitar sesgos por diferencias en escalas numéricas, para utilizar el algoritmo no supervisado DBSCAN.


    \textbf{DBSCAN}\textit{ (Density-Based Spatial Clustering of Applications with Noise)}, el cual agrupa observaciones en función de la densidad de los datos, sin necesidad de definir previamente el número de grupos (clústers) y permite identificar puntos atípicos (outliers).

    Además, para evaluar la calidad de los agrupamientos, se utilizó la métrica \textbf{Silhouette Score}, que mide la relación interna de los grupos (clústers) frente a su separación entre sí.

    Se utilizó un diagrama de caja para visualizar la distribución de la calificación final (G3) entre los distintos grupos formados por DBSCAN, lo que permitió observar las diferencias en rendimiento académico por clúster. {\textit{(Fig.~\ref{fig:boxplot_dbscan}, pág.~\pageref{fig:boxplot_dbscan})}}

    \item \underline{\textbf{Pronóstico:}} El conjunto de datos fue dividido en 80\% para entrenamiento y 20\% para prueba, esto se realizó utilizando la función \texttt{train\_test\_split()} de Scikit-Learn.
    
    
    Para la selección y aplicación de modelos supervisados, se aplicaron dos algoritmos de aprendizaje supervisado de tipo regresión:
    \begin{enumerate}[label=\textbf{\alph*)}]
    \item \textbf{Regresión Lineal Múltiple}, donde se ajustó una función lineal de la forma:
    $y=\beta _{0}+\beta _{1}x_{1}+\beta _{2}x_{2}+...+\beta _{n}x_{n}+\epsilon$
    
    
    Este modelo permite observar el peso de cada variable en la predicción del rendimiento final.

    \item \textbf{Bosque Aleatorio}, se aplicó como modelo complementario, capaz de capturar relaciones no lineales.
    
    
    Un método supervisado que construye múltiples árboles de decisión y promedia sus resultados para mejorar la precisión. 
\end{enumerate}


Ambos modelos fueron evaluados mediante las siguientes métricas:

\begin{itemize}[label=\textbf{\textendash}]
\item \textbf{MAE} \textit{(Mean Absolute Error)}: Error promedio entre los valores reales y predichos.

\item \textbf{RMSE} \textit{(Root Mean Squared Error)}: Representa la desviación estándar de los residuales (errores de predicción).
\end{itemize}

Por último, se realizaron visualizaciones con gráficos de dispersión y de barras para analizar la calidad de las predicciones y comparar el rendimiento de los modelos.

    \item \underline{\textbf{Diseño de Experimentos:}} Se evaluaron tres tamaños de partición para el conjunto de prueba: 20\%, 30\% y 40\%, con el fin de analizar su impacto en el desempeño de las variables.
    
    
    Además, se utilizaron los dos modelos supervisados utilizados anteriormente \textit{(Regresión Lineal Múltiple y Bosque Aleatorio)} agregando a esto las métricas junto con $R^2$ (Coeficiente de determinación).
\end{enumerate}


\section{Resultados}

\subsection*{Tipo de Variables}
Se sustituyeron las variables de interés en una prueba rápida de normalidad gráfico Q-QPlot. 

% Primera fila de imágenes
\begin{figure}[h]
    \centering
    \begin{minipage}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{graficos/qqplot.age.pdf}
        \caption{\centering \small Gráfico QQ para la variable Edad}
        \label{fig:gra1}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{graficos/qqplot.studytime.pdf}
        \caption{\centering \small Gráfico QQ para la variable Tiempo de Estudio}
        \label{fig:gra2}
    \end{minipage}
\end{figure}

% Segunda fila de imágenes
\begin{figure}[h]
    \centering
    \begin{minipage}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{graficos/qqplot.failures.pdf}
        \caption{\centering \small Gráfico QQ para la variable Materias Reprobadas}
        \label{fig:gra3}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{graficos/qqplot.absences.pdf}
        \caption{\centering \small Gráfico QQ para la variable Faltas}
        \label{fig:gra4}
    \end{minipage}
\end{figure}


\begin{figure}[h]
    \centering
    \begin{minipage}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{graficos/qqplot.G1.pdf}
        \caption*{\small (a)}
        \label{fig:gra5}
    \end{minipage}
    \hspace{0.05\textwidth}
    \begin{minipage}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{graficos/qqplot.G2.pdf}
        \caption*{\small (b)}
        \label{fig:gra6}
    \end{minipage}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{graficos/qqplot.G3.pdf}
    \caption*{\small (c)}
    \label{fig:gra7}

    \caption{Gráficas QQ variables: G1, G2 y G3 (calificaciones períodos)}
    \label{fig:tres-graficos}
\end{figure}

Al ver los resultados de cada variable se concluye que son \textbf{datos no paramétricos}.

\subsection*{Estadísticos Descriptivos}

\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{c|ccccccc}
 &
  \cellcolor[HTML]{DAE8FC}\textbf{age} &
  \cellcolor[HTML]{DAE8FC}\textbf{studytime} &
  \cellcolor[HTML]{DAE8FC}\textbf{failures} &
  \cellcolor[HTML]{DAE8FC}\textbf{absences} &
  \cellcolor[HTML]{DAE8FC}\textbf{G1} &
  \cellcolor[HTML]{DAE8FC}\textbf{G2} &
  \cellcolor[HTML]{DAE8FC}\textbf{G3} \\ \hline
\textbf{count} & \textit{395} & \textit{395} & \textit{395} & \textit{395} & \textit{395} & \textit{395} & \textit{395} \\
\rowcolor[HTML]{EFEFEF} 
\textbf{mean}  & 16.6962      & 2.0354       & 0.3341       & 5.7088       & 10.9088      & 10.7139      & 10.4151      \\
\textbf{std}   & 1.2760       & 0.8392       & 0.7436       & 8.0030       & 3.3191       & 3.7615       & 4.5814       \\
\rowcolor[HTML]{EFEFEF} 
\textbf{min}   & 15           & 1            & 0            & 0            & 3            & 0            & 0            \\
\textbf{25\%}  & 16           & 1            & 0            & 0            & 8            & 9            & 8            \\
\rowcolor[HTML]{EFEFEF} 
\textbf{50\%}  & 17           & 2            & 0            & 4            & 11           & 11           & 11           \\
\textbf{75\%}  & 18           & 2            & 0            & 8            & 13           & 13           & 14           \\
\rowcolor[HTML]{EFEFEF} 
\textbf{max}   & 22           & 4            & 3            & 75           & 19           & 19           & 20          
\end{tabular}%
}
\caption{Estadísticos Descriptivos}
\label{tab:estadisticos_descriptivos}
\end{table}

\subsection*{Correlación}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{graficos/matriz.corr.pdf}
    \caption{\small Matriz de Correlación}
    \label{fig:correlacion}
\end{figure}

Observaciones: 
\begin{itemize}[label=\textendash]
    \item La mayoría de las variables tienen una correlación positiva moderada.
    \item Las variables \textit{G1, G2 y G3} (calificaciones de los periodos), tienen una correlación positiva y fuerte entre ellas.
    \item La variable \textit{failures} (número de materias reprobadas anteriormente), es la que se muestra con una mayor correlación negativa en comparación con las demás.
\end{itemize}

\subsection*{Prueba de Hipótesis}

\subsubsection*{Efecto del número de faltas en la calificación final}

Con el objetivo de evaluar si el número de faltas escolares \textit{(absences)} tiene un efecto significativo sobre la calificación final del estudiante \textit{(G3)}, se realizó una prueba no paramétrica de Mann–Whitney U. Esta prueba se aplicó debido a que las distribuciones no cumplían con los supuestos de normalidad.

\begin{center}
\begin{tabular}{rl}
$H_0$:& No hay diferencia significativa en $G3$ entre los grupos. \\
$H_1$:& Hay diferencia significativa en $G3$ entre los grupos.
\end{tabular}
\end{center}

La muestra se dividió en dos grupos, tomando como punto de corte la media de faltas en el conjunto de datos:
\begin{itemize}
    \item Grupo de faltas bajas: Estudiantes con un número de faltas inferior a la media.
    \item Grupo de faltas altas: Estudiantes con un número de faltas igual o superior a la media.
\end{itemize}

Se compararon las calificaciones finales \textit{(G3)} de ambos grupos. Los resultados fueron los siguientes:
\begin{itemize}[label=\textendash]
    \item Media de G3 en el grupo de faltas bajas: 10.17
    \item Media de G3 en el grupo de faltas altas: 10.84
    \item Estadístico U = 18,595
    \item Valor-p = 0.7019
\end{itemize}

Dado que el valor-p (0.7) es mayor a 0.05, \textbf{no se rechaza la hipótesis nula}. 

Lo que indica que no existe una diferencia estadísticamente significativa en las calificaciones finales entre los estudiantes con menos faltas y aquellos con más faltas. 

\begin{figure}[h]
    \centering
    \caption{Diagrama de Caja - Comparación de Faltas y Nota Final (G3)}
    \label{fig:boxplot}
    \includegraphics[width=0.9\textwidth]{graficos/boxplot.Abs-G3.pdf}
\end{figure}

En la {gráfica ~\ref{fig:boxplot}, pag.~\pageref{fig:boxplot}} se comparan las calificaciones finales (G3) entre los dos grupos de estudiantes con número de faltas bajas y altas. 


Ambos grupos presentan una media muy similar, el número de faltas no parece afectar de forma clara la nota final, lo que concuerda con los resultados de la prueba estadística realizada, donde no se encontró una relación significativa entre las ausencias y el rendimiento final.


\subsection*{Selección de Características}

A través de distintos métodos de selección de características, se identificaron las variables más relevantes para predecir la calificación final (G3) de los estudiantes.
\begin{itemize}[label=\textbf{\textendash}]

\item {\textbf{ANOVA \textit{(valor F)} -}
Las variables con mayor relevancia estadística lineal para predecir G3 fueron:
    \begin{itemize}[label=\--] % Guion doble como viñeta
    \item \textbf{G2} (calificación del segundo periodo)
    \item \textbf{G1} (calificación del primer periodo)
    \item \textbf{Failures} (número de materias reprobadas)
    \end{itemize}
    
\item \textbf{Varianza - }
Las variables G1 \textit{(calificación del primer periodo)} y failures \textit{(número de materias reprobadas)} presentaron una varianza considerable, lo cual respalda su utilidad al aportar información a los modelos. En cambio, variables como higher mostraron baja varianza, aunque se mantuvieron por su valor interpretativo.

\item \textbf{Información mutua - }
Este análisis mostró que variables como studytime, absences y higher resaltan, aunque no tan fuertes con el valor F, tienen una dependencia no lineal significativa con G3.

\begin{table}[h]
\centering
\begin{tabular}{r|ccc}
\textbf{} & \cellcolor[HTML]{DAE8FC}\textbf{valor\_f} & \cellcolor[HTML]{DAE8FC}\textbf{varianza} & \cellcolor[HTML]{DAE8FC}\textbf{mir} \\ \hline
\textbf{G2}        & 1775.7075 & 0.0331 & 0.0382 \\
\rowcolor[HTML]{EFEFEF} 
\textbf{G1}        & 705.8422  & 0.0780 & 0.0196 \\
\textbf{failures}  & 58.6716   & 0.0612 & 0.0482 \\
\rowcolor[HTML]{EFEFEF} 
\textbf{higher}    & 13.5349   & 0.0113 & 0.1289 \\
\textbf{age}       & 10.5354   & 0.0480 & 0      \\
\rowcolor[HTML]{EFEFEF} 
\textbf{studytime} & 3.7968    & 0.0429 & 0.8105 \\
\textbf{absences}  & 0.4614    & 0.0390 & 1.3948
\end{tabular}
\caption{Resultados: ANOVA-Varianza-MIR}
\label{tab:VALOR F-VAR}
\end{table}


\item \textbf{Selección exhaustiva \textit{(EFS)} - }}
El método EFS identificó que la mejor combinación de variables para minimizar el error fue:
    \begin{itemize}[label=\--]
    \item \textbf{Failures} (número de materias reprobadas)
    \item \textbf{G2} (calificación del segundo periodo)
    \end{itemize}

Esto coincide con los hallazgos previos, reforzando su importancia como predictores clave del rendimiento final. {\textit{(Fig.~\ref{fig:efs}, pag.~\pageref{fig:efs})}}

\begin{figure}[]
    \centering
    \caption{Selección exhaustiva (EFS)}
    \label{fig:efs}
    \includegraphics[width=0.6\textwidth]{graficos/efs.pdf}
\end{figure}

\item {\textbf{Conclusión de la selección de variables}}


Variables predictoras:
    \begin{itemize}[label=\textbf{\--}]
    \item Studytime (tiempo de estudio).
    \item Absences (faltas).
    \item Failures (materías reprobadas).
    \item G1 (calificación primer periodo).
    \item G2 (calificación segundo periodo).
    \end{itemize}
Variable de respuesta:
    \begin{itemize}[label=\textbf{\--}]
    \item G3 (nota final del curso).
    \end{itemize}
  
\end{itemize}

\subsection*{Agrupamiento de datos}

Dado los resultados previos se restablecen las variables a trabajar, por lo que en este apartado se aplicará un algoritmo no supervisado para conocer mejor su densidad. Las variables fueron estandarizadas utilizando StandardScaler, con el fin de evitar sesgos por diferencias en escalas numéricas.

\subsubsection*{Algoritmo no supervisado: \textbf{DBSCAN}} 

DBSCAN (Density-Based Spatial Clustering of Applications with Noise), este es un método de agrupamiento basado en densidad porque encuentra un número de grupos (clústers) comenzando por una estimación de la distribución de densidad de los nodos correspondientes~\citep{datascientest_dbscan_2023}.


\begin{itemize}
\item \textit{\textbf{Modelo matemático de DBSCAN}}
\end{itemize}

DBSCAN agrupa puntos en regiones de alta densidad y clasifica como valores atípicos (outliers) aquellos que se encuentran en zonas de baja densidad.  
Los parámetros principales son:
\begin{itemize}[label=\--]
\item \textit{eps($\epsilon$):} radio de vecindad, es decir, la distancia máxima para que dos puntos se consideren vecinos.
\item \textit{min pts:} número mínimo de puntos requeridos para que una región se considere densa, sirve para formar un clúster (grupo).
\end{itemize}

El algoritmo comienza seleccionando un punto no visitado y determina si tiene al menos puntos (min pts) dentro de la distancia eps ($\epsilon$). Si es así, se forma un clúster y se expanden los puntos vecinos densos, de lo contrario, el punto se clasifica como ruido (outlier).  


Así, DBSCAN identifica automáticamente grupos de forma arbitraria y detecta valores atípicos.


\begin{itemize}
    \item \textit{\textbf{¿Por qué DBSCAN conviene para estos datos?}}
\end{itemize}

En el conjunto de datos Student Performance, las características como tiempo de estudio, ausencias, calificaciones y número de materias reprobadas tienden a tener una alta diversidad agregando las variables de ausencias extremas o bajo rendimiento muy marcado.


-No requiere conocer a priori el número de clústers (grupos), lo cual es práctico dado que no se sabe cuántos perfiles de estudiantes podrían existir.  


-Detecta automáticamente casos atípicos, ayudando a identificar estudiantes con comportamientos extremos (por ejemplo, altos niveles de ausencias).

\begin{itemize}
    \item \textit{\textbf{{Silhouette Score}}}
\end{itemize}

Se utilizó la métrica Silhouette Score como estrategia para identificar la cantidad óptima de grupos en los datos, es adecuada para algoritmos como DBSCAN, ya que se refiere a un método de interpretación y validación de la coherencia dentro del análisis de grupos.   

Esta métrica evalúa qué tan bien está asignado cada punto dentro de su grupo donde el valor oscila entre -1 a 1, donde un valor alto (cerca del 1) indica que el objeto está bien emparejado con su propio cúmulo \citep{WikipediaSilhouetteClustering}.

\begin{itemize}
    \item \textit{\textbf{Aplicación - Resultados}}
\end{itemize}
Tras evaluar múltiples configuraciones del parámetro eps ($\epsilon$), se identificó que la configuración óptima fue:

\begin{itemize}[label=\textbf{\--}]
    \item eps ($\epsilon$)= 2.0
    \item min pts (\texttt{min\_samples})= 5
    \item Número de clústers encontrados: 2
    \item Número de outliers detectados: 6
    \item Silhouette Score: Se obtuvo un valor aceptable (0.521), lo que sugiere una separación clara entre los grupos formados.
\end{itemize}


\textbf{Descripción de los Clústers} 


El algoritmo identificó tres grupos:

\begin{enumerate}[label=(\alph*)]
    \item \textbf{Clúster 0}

    \begin{itemize}
        \item Número de estudiantes: 372
        \item Perfil: Estudiantes con buen rendimiento académico (promedio $G3 \approx 10.6$), pocas ausencias, pocas materias reprobadas y alta motivación para continuar estudios superiores. Representan el grupo más estable y exitoso.
    \end{itemize}
    
    \item \textbf{Clúster 1}

    \begin{itemize}
        \item Número de estudiantes: 17
        \item Perfil: Estudiantes con bajo rendimiento académico (promedio $G3 \approx 6.7$), mayor número de materias reprobadas y escaso interés en educación superior. Este grupo podría representar estudiantes en riesgo académico.
    \end{itemize}
    
    \item \textbf{Clúster -1 (outliers)}

    \begin{itemize}
        \item Número de estudiantes: 6
        \item Perfil: Estudiantes con un número significativamente alto de faltas ($\approx 34$), comportamiento atípico frente al resto. Pueden estar influenciados por factores externos que afectan su rendimiento.
    \end{itemize}
\end{enumerate}

\begin{figure}[H]
    \centering
    \caption{\small DBSCAN}
    \label{fig:boxplot_dbscan}
    \includegraphics[width=0.8\textwidth]{graficos/boxplot_dbscan.pdf}
\end{figure}


\subsection*{Pronóstico}

\subsubsection*{Algoritmo supervisado: \textbf{Regresión Lineal}}


Para este proyecto se seleccionó un modelo de \textbf{regresión lineal múltiple}, una técnica supervisada que busca modelar la relación entre una variable dependiente (en este caso, la calificación final \textit{G3}) y un conjunto de variables independientes \textit{(tiempo de estudio, fallos previos, seguimiento de estudios, inasistencias, y las calificaciones previas (G1 y G2))}.


Este modelo asume que existe una relación lineal entre las variables predictoras y la variable de respuesta, y tiene la siguiente forma general~\citep{geeksforgeeks_linear_regression_2025}:

\begin{center}
    $y=\beta _{0}+\beta _{1}x_{1}+\beta _{2}x_{2}+...+\beta _{n}x_{n}+\epsilon$
\end{center}

Donde:
\begin{itemize}[label=\--]
\item \textit{Variable dependiente} ($y$): Es la variable que se quiere predecir.
\item \textit{Variables independientes $x_{1},x_{2},...,x_{n}$:} Son las variables que se utilizan para predecir la variable dependiente.
\item \textit{Coeficientes de regresión $\beta _{0},\beta _{1},...,\beta _{n}$:}
  
    \begin{itemize}
        \item $\beta _{0}$ (intercepto): Es el valor predicho de '$y$' cuando todas las variables independientes son cero.
        \item $\beta _{i} (i>0)$: Miden el cambio en la variable dependiente '$y$' por cada cambio de una unidad en la variable independiente correspondiente, manteniendo las demás variables constantes.
    \end{itemize}

\item \textit{Término de error $\epsilon$:} Representa la variabilidad en '$y$' y captura las diferencias entre los valores predichos y los reales.
\end{itemize}

\begin{itemize}
    \item \textit{\textbf{Justificación del Modelo}}
\end{itemize}

La regresión lineal múltiple fue elegida como modelo base por varias razones:

\begin{itemize}[label=\--]
\item \textit{Relación entre variables:} Algunas variables como G1 y G2, tienen una relación evidente con G3, lo cual favorece un modelo lineal.
\item \textit{Simplicidad e interpretabilidad:} Es fácil de implementar y analizar, permite entender cómo cada variable influye en el resultado.
\item \textit{Línea base útil:} Sirve como punto de partida para comparar otros modelos más complejos. Si la regresión lineal da buenos resultados, puede ser suficiente en ciertos contextos.
\end{itemize}


\begin{itemize}
    \item \textit{\textbf{Métricas de Evaluación}}
    
    
    Para medir el desempeño del modelo se utilizaron dos métricas comunes en problemas de regresión~\citep{chugh_mae_mse_rmse_adjusted_r2_2020}:
\end{itemize}

\begin{itemize}[label=\textbf{\--}]
    \item \textbf{MAE} \textit{(Mean Absolute Error)}:  
  Es el promedio de los errores absolutos entre las predicciones y los valores reales.\\
  Indica cuánto se desvía en promedio la predicción del valor real.  


    \underline{Formula}= $(1/n) \Sigma |yᵢ - \hat{y_i}|$
  \begin{center}
      \textit{Cuanto menor es el MAE, mejor es el modelo.}
  \end{center}
  
    \item \textbf{RMSE} \textit{(Root Mean Squared Error)}:
  Es la raíz cuadrada del promedio del error cuadrático.\\
  Representa la desviación estándar de los residuales (errores de predicción).  
  
    \underline{Formula} = $\sqrt{(1/n) \Sigma (yᵢ - \hat{y_i})^2}$
\begin{center}
  \textit{Un valor bajo de RMSE indica un buen ajuste.} 
  \end{center}

\end{itemize}


\begin{itemize}
    \item \textit{\textbf{Aplicación - Resultados}}\\
    El conjunto de datos se dividió en un 80\% para entrenamiento y un 20\% para prueba, utilizando la función \texttt{train\_test\_split()} de Scikit-Learn.
\end{itemize}

\begin{enumerate}[label=\textbf{\arabic*.}]
    \item \textbf{Modelo de Regresión Lineal Múltiple}

La regresión asume una relación lineal entre las variables predictoras y la variable de respuesta.
    
    
El modelo ajustado obtuvo la siguiente ecuación:
\begin{align*}
y =\;& -1.872 - 0.0814\,(\text{studytime}) - 0.4309\,(\text{failures}) \\
    & + 0.0397\,(\text{absences}) + 0.3027\,(\text{higher}) \\
    & + 0.143\,(\text{G1}) + 0.9791\,(\text{G2})
\end{align*}

Los resultados indican que las calificaciones previas \textit{(G1 y G2)} son los predictores con mayor peso positivo sobre la nota final, mientras que el número de materias reprobadas \textit{(failures)} tiene un efecto negativo.

En cuanto al desempeño, las métricas de evaluación fueron:
\begin{itemize}[label=\--]
    \item \underline{MAE} (Mean Absolute Error): 1.33
    \item \underline{RMSE} (Root Mean Squared Error): 2.11
\end{itemize}

Estos valores reflejan un error promedio de aproximadamente 1.3 puntos en la predicción de la calificación final. Aunque el modelo logra capturar la tendencia general, se observa cierta dispersión entre los valores reales y los predichos.

La primera gráfica en la {fig.~\ref{fig:rlineal_vs_rforest}, pág.~\pageref{fig:rlineal_vs_rforest}} muestra la relación entre los valores reales y los predichos para el modelo lineal, donde la dispersión alrededor de la línea roja (predicción perfecta) evidencia la presencia de errores de estimación en varios puntos.

\item \textbf{Bosque Aleatorio}

Se aplicó el modelo Bosque Aleatorio \textit{(Random Forest Regressor)}, un método supervisado que construye múltiples árboles de decisión y promedia sus resultados para mejorar la precisión. 


En comparación con la regresión lineal, el modelo de Bosque Aleatorio presenta menores errores, lo que indica una mejor capacidad predictiva. La dispersión de los valores reales y predichos se aproxima más a la línea ideal, reflejando una mayor precisión en la estimación de la calificación final.


\begin{itemize}[label=\--]
    \item \underline{Regresión Lineal:} MAE \approx 1.33 - RMSE \approx 2.11
    \item \underline{Bosque Aleatorio}: MAE \approx 1.06 - RMSE \approx 1.64
\end{itemize}
\end{enumerate}



\begin{figure}[H]
    \centering
    \includegraphics[width=1.05\linewidth]{graficos/rlineal_vs_rforest.pdf}
    \caption{Regresión Lineal - Bosque Aleatorio}
    \label{fig:rlineal_vs_rforest}
\end{figure}

La Regresión Lineal Múltiple resulta útil como modelo base por su simplicidad e interpretabilidad, aunque su precisión es limitada ante comportamientos no lineales del conjunto de datos.
Por el contrario, el modelo de Bosque Aleatorio demuestra un rendimiento superior en las métricas, gracias a su capacidad para modelar relaciones no lineales y manejar interacciones entre variables.


Ambos modelos permiten predecir la calificación final de los estudiantes con un error promedio menor a dos puntos, lo cual se considera un nivel de precisión aceptable para este tipo de datos educativos

\subsection*{Diseño de Experimentos}

Se realizó un diseño factorial considerando tres elementos: modelo, normalización y tamaño del conjunto de prueba, evaluando su impacto sobre MAE, RMSE y R².

\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{c|c|c}
\rowcolor[HTML]{DAE8FC} 
\textbf{Factor} & \textbf{Descripción}                & \textbf{Niveles} \\ \hline
Modelo                        & Tipo de algoritmo utilizado            & Regresión Lineal / Bosque Aleatorio \\
Normalización   & Escalado de las variables numéricas & Sí / No          \\
Tamaño del conjunto de prueba & Proporción de datos usados para prueba & 0.2 / 0.3 / 0.4                    
\end{tabular}%
}
\caption{\small Diseño de experimento}
\label{tab:DiseñoExp}
\end{table}

La normalización se aplicó únicamente a las variables numéricas continúas (studytime, failures, absences, G1, G2), excluyendo higher \textit{(seguimiento de estudios)} por ser binaria.



Los resultados fueron los siguientes, presentados de mejor a peor por la métrica R²: 
\begin{table}[H]
\resizebox{\textwidth}{!}{%
\begin{tabular}{lllllll}
 &
  \cellcolor[HTML]{DAE8FC}\textbf{Modelo} &
  \cellcolor[HTML]{DAE8FC}\textbf{Normalización} &
  \cellcolor[HTML]{DAE8FC}\textbf{Test Size} &
  \cellcolor[HTML]{DAE8FC}\textbf{MAE} &
  \cellcolor[HTML]{DAE8FC}\textbf{RMSE} &
  \cellcolor[HTML]{DAE8FC}\textbf{R2} \\ \hline
9  & RandomForest & No & 0.4 & 1.0032 & 1.5993 & 0.8834 \\
\rowcolor[HTML]{EFEFEF} 
5  & RandomForest & No & 0.3 & 0.9923 & 1.6152 & 0.8813 \\
11 & RandomForest & Sí & 0.4 & 1.0267 & 1.6149 & 0.8812 \\
\rowcolor[HTML]{EFEFEF} 
7  & RandomForest & Sí & 0.3 & 1.0138 & 1.6380 & 0.8779 \\
1  & RandomForest & No & 0.2 & 1.0576 & 1.6442 & 0.8681 \\
\rowcolor[HTML]{EFEFEF} 
3  & RandomForest & Sí & 0.2 & 1.0911 & 1.6784 & 0.8626 \\
8  & Lineal       & No & 0.4 & 1.2541 & 2.0117 & 0.8157 \\
\rowcolor[HTML]{EFEFEF} 
10 & Lineal       & Sí & 0.4 & 1.2541 & 2.0117 & 0.8157 \\
6  & Lineal       & Sí & 0.3 & 1.2754 & 2.0794 & 0.8033 \\
\rowcolor[HTML]{EFEFEF} 
4  & Lineal       & No & 0.3 & 1.2754 & 2.0794 & 0.8033 \\
2  & Lineal       & Sí & 0.2 & 1.3291 & 2.1102 & 0.7828 \\
\rowcolor[HTML]{EFEFEF} 
0  & Lineal       & No & 0.2 & 1.3291 & 2.1102 & 0.7828
\end{tabular}%
}
\caption{Resultados - Diseño de Experimento}
\label{tab:RESDiseñoExp}
\end{table}

Observaciones: 
\begin{itemize}
    \item El modelo Bosque Aleatorio fue superior a la Regresión Lineal en todas las combinaciones de factores.
    \item Incrementar el tamaño del conjunto de prueba de 20\% a 40\% permitió que el modelo Bosque Aleatorio mostrará su mejor desempeño ($R^2$ = 0.8834).
    \item La normalización de variables numéricas no generó mejoras significativas en Bosque Aleatorio, aunque es más relevante para Regresión Lineal.
\end{itemize}

Comparando los resultados obtenidos para cada combinación de factores y recordando qué, cuanto menores sean MAE y RMSE, y mayor sea $R^2$, mejor será el modelo. 


\textbf{El modelo con mejor desempeño global fue el de Bosque Aleatorio sin normalización y con un tamaño de prueba del 40\%}, alcanzando un $R^2$ = 0.8834, lo que indica aproximadamente el 88\% de la variabilidad en las calificaciones finales.




\section{Conclusiones y discusión}

El uso de técnicas estadísticas y métodos de aprendizaje automático permitió identificar y cuantificar los factores relacionados con el estilo de vida, comportamiento académico y bienestar personal que influyen de manera significativa en el rendimiento académico de los 
estudiantes, medido a través de la calificación final. 


Como se vio en la matriz de correlación, las variables G1, G2 \textit{(calificaciones de periodos)} tienen una correlacion positiva-fuerte entre ellas y 'Failures' \textit{(número de materías reprobadas)} con una mayor correlación negativa en comparación con las demás, estás mismas fueron la mejor combinación de variables para minimizar el error en el método de Selección exhaustiva (EFS). 

Si bien las variables se muestran de buena manera en las gráficas Q-QPlot, se determinó que los datos no son paramétricos, así al realizar la prueba de hipótesis se utilizó la prueba Mann–Whitney U debido a que no se cumplen los supuestos de normalidad y, según este análisis, el número de faltas escolares no parece tener un efecto determinante en el rendimiento final medido por G3.


El uso del algoritmo DBSCAN permitió segmentar a los estudiantes en grupos según su perfil académico y comportamiento escolar, estos resultados pueden ser útiles para:

\begin{itemize}
    \item Confirmar patrones de éxito académico (Clúster 0, promedio calif. final $\approx 10.6$), lo cual puede servir de referencia para prácticas educativas efectivas.
    \item Identificar estudiantes en riesgo (Clúster 1, promedio calif. final $\approx 6.7$) y ofrecer apoyo focalizado.
    \item Analizar valores atípicos (Clúster -1, faltas $\approx 34$), cuyas características podrían requerir intervención específica o estudio adicional.
\end{itemize}

La técnica de agrupamiento junto con el análisis de rendimiento ofrecen una herramienta útil para identificar perfiles de estudiantes, detectar casos en riesgo y orientar estrategias educativas. \vspace{1em}

Mediante la aplicación de un modelo de regresión lineal múltiple, se determinó que la ecuación del modelo es el siguiente:
\begin{align*}
y =\;& -1.872 - 0.0814\,(\text{studytime}) - 0.4309\,(\text{failures}) \\
    & + 0.0397\,(\text{absences}) + 0.3027\,(\text{higher}) \\
    & + 0.143\,(\text{G1}) + 0.9791\,(\text{G2})
\end{align*}

El modelo obtenido presenta un coeficiente de determinación $R^2=0.783$, lo que indica que el 78\% de la variabilidad en las 
calificaciones puede explicarse por las variables seleccionadas.


Enlazado a esto, el diseño factorial permitió evaluar de manera sistemática el efecto del tipo de modelo, la normalización de variables y el tamaño del conjunto de prueba sobre el desempeño predictivo, medido mediante las métricas MAE, RMSE y R².
Donde el modelo con mejor desempeño fue el de Bosque Aleatorio sin normalización y con un tamaño de prueba del 40\%, lo cual fue relevante como una opción más robusta y precisa para predecir las calificaciones finales dentro de las condiciones evaluadas con un 88\% de variabilidad en las calificaciones finales (R²). \vspace{1em}

En conclusión, este estudio evidencia que la combinación de enfoques estadísticos y de aprendizaje automático puede ser una herramienta fuerte para mejorar la comprensión del proceso educativo, apoyar la toma de decisiones pedagógicas y diseñar intervenciones más efectivas que promuevan el desarrollo académico integral de los estudiantes.

\newpage
\nocite{mishraEA2024}
\nocite{Chong2017}
\nocite{WikipediaMannWhitneyU}
\nocite{Brownlee2019}
%\bibliographystyle{apalike}
\bibliographystyle{unsrtnat}
\bibliography{referencias}

\end{document}

